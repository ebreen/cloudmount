---
phase: 02-core-mount-browse
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified: [
  "Daemon/CloudMountDaemon/src/cache/metadata.rs",
  "Daemon/CloudMountDaemon/src/cache/mod.rs",
  "Daemon/CloudMountDaemon/src/fs/b2fs.rs"
]
autonomous: true

must_haves:
  truths:
    - "Metadata cache reduces B2 API calls by 80%+"
    - "Directory listings return from cache when fresh"
    - "Cache TTL of 5 minutes prevents stale data"
    - "File attributes are cached per-inode"
    - "Cache invalidation works for explicit unmount"
  artifacts:
    - path: "Daemon/CloudMountDaemon/src/cache/metadata.rs"
      provides: "MetadataCache with TTL support"
      exports: ["MetadataCache", "get", "insert", "invalidate"]
    - path: "Daemon/CloudMountDaemon/src/fs/b2fs.rs"
      provides: "Updated B2Filesystem with cache integration"
  key_links:
    - from: "fs/b2fs.rs"
      to: "cache/metadata.rs"
      via: "MetadataCache for FileAttr storage"
      pattern: "metadata_cache.get(ino)"
    - from: "cache/metadata.rs"
      to: "moka::future::Cache"
      via: "Moka cache with TTL"
      pattern: "Cache::builder().time_to_live"
---

<objective>
Add metadata caching layer using Moka to dramatically improve directory browsing performance and reduce B2 API rate limit exposure.

Purpose: Without caching, every Finder refresh triggers multiple B2 API calls causing slow performance and potential rate limiting. This plan makes browsing feel native.

Output: High-performance metadata cache integrated into the FUSE filesystem.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-core-mount-browse/02-RESEARCH.md

# Prior plans (when available)
@.planning/phases/02-core-mount-browse/02-01-SUMMARY.md
@.planning/phases/02-core-mount-browse/02-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement metadata cache with Moka</name>
  <files>
    Daemon/CloudMountDaemon/src/cache/metadata.rs
    Daemon/CloudMountDaemon/src/cache/mod.rs
  </files>
  <action>
Implement the metadata caching layer (from RESEARCH.md Pattern 3):

1. Create `src/cache/metadata.rs` with `MetadataCache` struct:
   ```rust
   use moka::future::Cache;
   use std::time::Duration;
   use fuser::FileAttr;

   pub struct MetadataCache {
       // Cache inode -> FileAttr
       attr_cache: Cache<u64, FileAttr>,
       // Cache directory listings: (parent_ino, prefix) -> Vec<DirEntry>
       dir_cache: Cache<(u64, String), Vec<DirEntry>>,
   }
   ```

2. Implement cache configuration:
   - TTL: 5 minutes (300 seconds) for directory listings
   - TTL: 10 minutes (600 seconds) for file attributes
   - Max capacity: 10,000 entries (matches B2 list max)
   - Use time_to_live and time_to_idle for both caches

3. Implement cache methods:
   ```rust
   impl MetadataCache {
       pub fn new() -> Self {
           Self {
               attr_cache: Cache::builder()
                   .max_capacity(10000)
                   .time_to_live(Duration::from_secs(600))
                   .time_to_idle(Duration::from_secs(120))
                   .build(),
               dir_cache: Cache::builder()
                   .max_capacity(1000)
                   .time_to_live(Duration::from_secs(300))
                   .time_to_idle(Duration::from_secs(60))
                   .build(),
           }
       }

       pub async fn get_attr(&self, ino: u64) -> Option<FileAttr> {
           self.attr_cache.get(&ino).await
       }

       pub async fn insert_attr(&self, ino: u64, attr: FileAttr) {
           self.attr_cache.insert(ino, attr).await;
       }

       pub async fn get_dir(&self, parent_ino: u64, prefix: &str) -> Option<Vec<DirEntry>> {
           self.dir_cache.get(&(parent_ino, prefix.to_string())).await
       }

       pub async fn insert_dir(&self, parent_ino: u64, prefix: &str, entries: Vec<DirEntry>) {
           self.dir_cache.insert((parent_ino, prefix.to_string()), entries).await;
       }

       pub async fn invalidate(&self, ino: u64) {
           self.attr_cache.invalidate(&ino).await;
       }

       pub async fn invalidate_dir(&self, parent_ino: u64, prefix: &str) {
           self.dir_cache.invalidate(&(parent_ino, prefix.to_string())).await;
       }

       pub async fn clear(&self) {
           self.attr_cache.invalidate_all();
           self.dir_cache.invalidate_all();
       }
   }
   ```

4. Create `src/cache/mod.rs` exporting metadata module

Note: DirEntry needs to be Clone for Moka. Ensure it's defined in b2/types.rs with #[derive(Clone)].
  </action>
  <verify>
cd Daemon/CloudMountDaemon && cargo check --lib
  </verify>
  <done>
MetadataCache compiles with attr_cache and dir_cache, both use Moka with TTL configuration.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate cache into B2Filesystem</name>
  <files>
    Daemon/CloudMountDaemon/src/fs/b2fs.rs
  </files>
  <action>
Update B2Filesystem to use MetadataCache for all operations:

1. Update struct to include cache:
   ```rust
   pub struct B2Filesystem {
       inode_table: Mutex<InodeTable>,
       b2_client: B2Client,
       bucket_id: String,
       metadata_cache: MetadataCache,
   }
   ```

2. Update constructor:
   ```rust
   pub fn new(b2_client: B2Client, bucket_id: String) -> Self {
       Self {
           inode_table: Mutex::new(InodeTable::new()),
           b2_client,
           bucket_id,
           metadata_cache: MetadataCache::new(),
       }
   }
   ```

3. Update `getattr` with caching:
   ```rust
   fn getattr(&mut self, _req: &Request, ino: u64, _fh: Option<u64>, reply: ReplyAttr) {
       // Try cache first
       if let Some(attr) = self.metadata_cache.get_attr(ino) {
           reply.attr(&Duration::from_secs(1), &attr);
           return;
       }

       // Cache miss - fetch from B2
       let attr = self.fetch_attr_from_b2(ino);
       
       // Store in cache
       self.metadata_cache.insert_attr(ino, attr.clone());
       
       reply.attr(&Duration::from_secs(1), &attr);
   }
   ```

4. Update `readdir` with directory caching:
   ```rust
   fn readdir(&mut self, _req: &Request, ino: u64, _fh: u64, offset: i64, mut reply: ReplyDirectory) {
       let prefix = self.inode_table.lock().unwrap().get_path(ino).unwrap_or("").to_string();
       
       // Try directory cache
       if let Some(entries) = self.metadata_cache.get_dir(ino, &prefix) {
           // Add entries from cache
           for (i, entry) in entries.iter().enumerate().skip(offset as usize) {
               if reply.add(entry.ino, (i + 1) as i64, entry.name.clone(), entry.kind) {
                   break;
               }
           }
           reply.ok();
           return;
       }

       // Cache miss - fetch from B2
       let entries = self.fetch_dir_from_b2(ino, &prefix);
       
       // Store in cache
       self.metadata_cache.insert_dir(ino, &prefix, entries.clone());
       
       // Also cache individual file attributes
       for entry in &entries {
           if let Some(attr) = self.fetch_attr_for_entry(entry) {
               self.metadata_cache.insert_attr(entry.ino, attr);
           }
       }

       // Add to reply
       for (i, entry) in entries.iter().enumerate().skip(offset as usize) {
           if reply.add(entry.ino, (i + 1) as i64, entry.name.clone(), entry.kind) {
               break;
           }
       }
       reply.ok();
   }
   ```

5. Add helper methods:
   - `fetch_attr_from_b2(&self, ino: u64) -> FileAttr`
   - `fetch_dir_from_b2(&self, ino: u64, prefix: &str) -> Vec<DirEntry>`
   - `fetch_attr_for_entry(&self, entry: &DirEntry) -> Option<FileAttr>`

6. Handle cache invalidation:
   - Add method `invalidate_path(&self, path: &str)` for future write operations
   - For now, TTL handles freshness

CRITICAL: The cache is async (Moka::future::Cache) but FUSE callbacks are sync. Use `block_on` or spawn_blocking for cache operations. Consider using moka::sync::Cache instead for simpler integration.
  </action>
  <verify>
cd Daemon/CloudMountDaemon && cargo check --lib
  </verify>
  <done>
B2Filesystem uses MetadataCache in getattr and readdir, cache hits avoid B2 API calls.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add cache metrics and logging</name>
  <files>
    Daemon/CloudMountDaemon/src/cache/metadata.rs
    Daemon/CloudMountDaemon/src/fs/b2fs.rs
  </files>
  <action>
Add observability to the caching layer for debugging and performance monitoring:

1. Extend MetadataCache with metrics:
   ```rust
   pub struct CacheMetrics {
       pub attr_hits: AtomicU64,
       pub attr_misses: AtomicU64,
       pub dir_hits: AtomicU64,
       pub dir_misses: AtomicU64,
   }

   pub struct MetadataCache {
       attr_cache: Cache<u64, FileAttr>,
       dir_cache: Cache<(u64, String), Vec<DirEntry>>,
       metrics: CacheMetrics,
   }
   ```

2. Track hits and misses:
   ```rust
   pub async fn get_attr(&self, ino: u64) -> Option<FileAttr> {
       let result = self.attr_cache.get(&ino).await;
       if result.is_some() {
           self.metrics.attr_hits.fetch_add(1, Ordering::Relaxed);
       } else {
           self.metrics.attr_misses.fetch_add(1, Ordering::Relaxed);
       }
       result
   }
   ```

3. Add metrics reporting method:
   ```rust
   pub fn report_metrics(&self) {
       let attr_hits = self.metrics.attr_hits.load(Ordering::Relaxed);
       let attr_misses = self.metrics.attr_misses.load(Ordering::Relaxed);
       let dir_hits = self.metrics.dir_hits.load(Ordering::Relaxed);
       let dir_misses = self.metrics.dir_misses.load(Ordering::Relaxed);
       
       let attr_rate = if attr_hits + attr_misses > 0 {
           attr_hits as f64 / (attr_hits + attr_misses) as f64 * 100.0
       } else { 0.0 };
       
       let dir_rate = if dir_hits + dir_misses > 0 {
           dir_hits as f64 / (dir_hits + dir_misses) as f64 * 100.0
       } else { 0.0 };
       
       tracing::info!(
           "Cache metrics - Attr: {:.1}% hit rate ({} hits, {} misses), Dir: {:.1}% hit rate ({} hits, {} misses)",
           attr_rate, attr_hits, attr_misses, dir_rate, dir_hits, dir_misses
       );
   }
   ```

4. Add periodic metrics logging in main.rs:
   - Spawn a task that logs cache metrics every 60 seconds
   - Use tokio::time::interval

5. Add debug logging in FUSE callbacks:
   - Log cache hits at debug level
   - Log cache misses and B2 fetches at info level
   - Include inode number and path in logs

This helps verify caching is working and diagnose performance issues.
  </action>
  <verify>
cd Daemon/CloudMountDaemon && cargo build
  </verify>
  <done>
Cache metrics compile, logging shows hit/miss rates, periodic reporting task works.
  </done>
</task>

</tasks>

<verification>
Overall phase checks:
- [ ] `cargo build` passes
- [ ] MetadataCache uses Moka with TTL configuration
- [ ] B2Filesystem checks cache before B2 API calls
- [ ] Cache metrics track hit/miss rates
- [ ] Logging shows cache effectiveness
</verification>

<success_criteria>
1. MetadataCache provides get_attr/insert_attr with 10-minute TTL
2. MetadataCache provides get_dir/insert_dir with 5-minute TTL
3. B2Filesystem getattr checks cache first, falls back to B2 API
4. B2Filesystem readdir uses directory cache for listing
5. Cache metrics show hit rates for debugging
6. Build succeeds with all cache integration
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-mount-browse/02-03-SUMMARY.md`
</output>
